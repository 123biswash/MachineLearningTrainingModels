# -*- coding: utf-8 -*-
"""Copy of Lab 11: Train A DNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1AxKbEb6fLF0W0JB9a1hkG30Nd_qQkVg3

#### Copyright 2017 Google LLC.
"""

# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""# Lab 11: Train a DNN
**Learning Objectives:**
  * Train a DNN and explore the difference in performance as the DNN architecture is varied.
  
    
***As in Lab 10, you will need to go to previous labs to make use of functions provided in those labs. It is very important you start this lab early so you have plenty of time to get help if needed! This is especially important if you did not complete Lab 10.***

### Standard Set-up

We begin with the standard set-up as seen in the last lab again using the census data set.
"""

import math

from IPython import display
from matplotlib import cm
from matplotlib import gridspec
from matplotlib import pyplot as plt
import numpy as np
import pandas as pd
from mpl_toolkits.mplot3d import Axes3D
from sklearn import metrics
import tempfile
import tensorflow as tf
from tensorflow.contrib.learn.python.learn import learn_io, estimator
import urllib

# This line increases the amount of logging when there is an error.  You can
# remove it if you want less logging.
tf.logging.set_verbosity(tf.logging.ERROR)

# Set the output display to have two digits for decimal places, for display
# readability only and limit it to printing 15 rows.
pd.options.display.float_format = '{:.2f}'.format
pd.options.display.max_rows = 15


train_file = tempfile.NamedTemporaryFile()
urllib.urlretrieve("http://mlr.cs.umass.edu/ml/machine-learning-databases/adult/adult.data", train_file.name)

COLUMNS = ["age", "workclass", "sample_weight", "education", "education_num",
           "marital_status", "occupation", "relationship", "race", "gender",
           "capital_gain", "capital_loss", "hours_per_week", "native_country",
           "income_bracket"]
census_df = pd.read_csv(train_file, names=COLUMNS, skipinitialspace=True)

"""### Modifications Introduced for Lab 11

As in Lab 10, you are going to copy a lot of your code from previous labs to complete this lab. Some of the key things you need to add here are:

* Defining the input functions.
* Defining and using the methods for feature scaling and to prepare the features.
* Loading and generating the training, validation, and test data sets.
* Defining the method to compute the loss, plot the learning curve and ROC curves, and train the model.

You should be able to find and use functions from previous labs with little or no modifications.

There are a few key changes that we are going to make and we'll provide some code snippets to help you make the needed changes. The key changes in this lab are:
* You will just use the original features (with normalization) but without any bucketized features or crossed features.
* You will use a DNN (deep neural network) versus a linear model as we have in all of the previous labs.

### Setting Up the Feature Columns and Input Function for TensorFlow
As in the past labs, we define `input_fn` to define a `FeatureColumn` for each categorical and numerical feature, and then define `train_input_fn` to use the training data, `eval_input_fn` to use the validation data, and `test_input_fn` to use the test data.
"""

CATEGORICAL_COLUMNS = ["workclass", "education", "marital_status", "occupation",
                       "relationship", "race", "gender", "native_country"]
NUMERICAL_COLUMNS = ["age", "education_num", "capital_gain", "capital_loss",
                      "hours_per_week"]
LABEL = "income_over_50k"

def input_fn(dataframe):
  """Constructs a dictionary for the feature columns.

  Args:
    dataframe: The Pandas DataFrame to use for the input.
  Returns:
    The feature columns and the associated labels for the provided input.
  """
  # Creates a dictionary mapping each numerical feature column name (k) to
  # the values of that column stored in a constant Tensor.
  numerical_cols = {k: tf.constant(dataframe[k].values) 
                    for k in NUMERICAL_COLUMNS}
  # Creates a dictionary mapping each categorical feature column name (k)
  # to the values of that column stored in a tf.SparseTensor.
  categorical_cols = {k: tf.SparseTensor(
      indices=[[i, 0] for i in range(dataframe[k].size)],
      values=dataframe[k].values,
      dense_shape=[dataframe[k].size, 1])
                      for k in CATEGORICAL_COLUMNS}
  # Merges the two dictionaries into one.
  feature_cols = dict(numerical_cols.items() + categorical_cols.items())
  # Converts the label column into a constant Tensor.
  label = tf.constant(dataframe[LABEL].values)
  # Returns the feature columns and the label.
  return feature_cols, label

def train_input_fn():
  return input_fn(training_examples)

def eval_input_fn():
  return input_fn(validation_examples)

def test_input_fn():
  return input_fn(test_examples)

"""##Prepare Features

Here is a basic implementation of `PrepareFeatures` for you to use.  Feel free to modify this to use feature normalization other than just linear scaling.  

Note that for linear classification with just two labels, the labels must be 0 (think of this as false) and 1 (think of this as true).  Since `income_brackets` is a string, we must convert it to an integer. This can be done using a lambda function that outputs a Boolean  value, and then casts it to an integer. We have provided this for you.
"""

# Linearly rescales to the range [0, 1]
def linear_scale(series):
  min_val = series.min()
  max_val = series.max()
  scale = 1.0 * (max_val - min_val)
  return series.apply(lambda x:((x - min_val) / scale))

def prepare_features(dataframe):
  """Prepares the features for provided dataset.

  Args:
    dataframe: A Pandas DataFrame expected to contain the data.
  Returns:
    A new DataFrame that contains the features to be used for the model.
  """
  processed_features = dataframe.copy()
  for feature in NUMERICAL_COLUMNS:
    processed_features[feature] = linear_scale(dataframe[feature])
    
  # Convert the output target to 0 (for <=50k) and 1 (> 50k)
  processed_features[LABEL] = dataframe["income_bracket"].apply(
      lambda x: ">50K" in x).astype(int)
  
  return processed_features

"""### Load the Test Data

Like with the housing data, this data set has a specified [test data](https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test) that we can use at the end to look at the performance for our final classifier.  We will load it and do the pre-processing here but this should not be used in training or selecting any of the hyperparameters.
"""

test_file = tempfile.NamedTemporaryFile()
urllib.urlretrieve("http://mlr.cs.umass.edu/ml/machine-learning-databases/adult/adult.test", test_file.name)

census_df_test = pd.read_csv(test_file, names=COLUMNS, skipinitialspace=True, skiprows=1)
test_examples = prepare_features(census_df_test)

"""#Divide the provided data for training our model into training and validation sets

As we've done in the past, let's divide the data into a ***training set*** and ***validation set***.  There are 16281 examples so let's set aside 4000 for our validation data.  Let's not forget to randomize the order before splitting the data so that our validation set is a representative sample.
"""

census_df = census_df.reindex(np.random.permutation(census_df.index))
training_examples = prepare_features(census_df.head(12281))
validation_examples = prepare_features(census_df.tail(4000))

"""### Compute Loss

For classification problems, we generally would like our output to be a probability distribution over the possible classes.  When we have two classes the **log loss** is a measure of how close the predicted distribution is to the target distribution, and that is the metric that we will optimize. Again, we use the [sklearn metrics](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics) class.
"""

def compute_loss(model, input_fn, targets):
  """ Computes the log loss for training a linear classifier.
  
  Args:
    model: the trained model to use for making the predictions.
    input_fn: the input_fn to use to make the predicitons.
    targets: a list of the target values being predicted that must be the
             same length as predictions.
    
  Returns:
    The log loss for the provided predictions and targets.
  """      
  
  predictions = np.array(list(model.predict_proba(input_fn=input_fn)))
  return metrics.log_loss(targets, predictions[:, 1])

"""### Train Model

For the most part `define_linear_classifier` is like `define_linear_regressor` with the changes of using the log loss to optimize and the ROC curve to visualize the model quality.  As before we plot a learning curve to see if the model is converging, to help tune the learning rate, and to check if we are overfitting by looking at the loss on the validation data.
"""

def train_model(model, steps):
  """Trains a linear classifier.
  
  Args:
    model: The model to train.
    steps: A non-zero `int`, the total number of training steps.
    
  Returns:
    The trained model.
  """
  # In order to see how the model evolves as we train it, we divide the
  # steps into periods and show the model after each period.
  periods = 10
  steps_per_period = steps / periods
  
  # Train the model, but do so inside a loop so that we can periodically assess
  # loss metrics.  We store the training and validation losses so we can
  # generate a learning curve.
  print "Training model..."
  training_losses = []
  validation_losses = []

  for period in range (0, periods):
    # Call fit to train the model for steps_per_period steps.
    model.fit(input_fn=train_input_fn, steps=steps_per_period)
    
    # Compute the loss between the predictions and the correct labels, append
    # the training and validation loss to the list of losses used to generate
    # the learning curve after training is complete and print the current
    # training loss.
    training_loss = compute_loss(model, train_input_fn,
                                 training_examples[LABEL])
    validation_loss = compute_loss(model, eval_input_fn,
                                   validation_examples[LABEL])
    training_losses.append(training_loss) 
    validation_losses.append(validation_loss) 
    print "  Training loss after period %02d : %0.3f" % (period, training_loss)
      
  # Now that training is done print the final training and validation losses.  
  print "Final Training Loss: %0.3f" % training_loss
  print "Final Validation Loss: %0.3f" % validation_loss 
  
  # Generate a figure with the learning curve on the left and an ROC curve on
  # the right.
  plt.figure(figsize=(10, 5))
  plt.subplot(1, 2, 1)
  plt.title("Learning Curve (Loss vs time)")
  plot_learning_curve(training_losses, validation_losses)
  
  plt.subplot(1, 2, 2)
  plt.tight_layout(pad=1.1, w_pad=3.0, h_pad=3.0) 
  plt.title("ROC Curve on Validation Data")
  validation_probabilities = np.array(list(model.predict_proba(
    input_fn=eval_input_fn)))
  # ROC curve uses the probability that the label is 1.
  make_roc_curve(validation_probabilities[:, 1], validation_examples[LABEL])
   
  return model

"""##Setting up the Features

We will set things up showing you an example of how to set up each of the kind of features you will be using.  Then you can add in additional features.

####Categorical Feauture Columns with known values.

When the values are known you can simply use a line like below.  If you would view the weights, index 0 will be the first key provided, index 1, the next key,.....

```
      gender = tf.contrib.layers.sparse_column_with_keys(column_name="gender", keys=["Female", "Male"])
  
  ```
####Categorical Feature Columns without known values

Since you don't always know the possible values you can instead assign an index to each possible value via hashing where `hash_bucket_size` is the number of hash buckets used.

```
      education = tf.contrib.layers.sparse_column_with_hash_bucket("education", hash_bucket_size=100)
```

####Numerical Feature Columns
As we have seen in past labs, we can directly use numerical features as long as appropriate scaling has been applied. The provided implementation of `prepare_features` linearly scales all numerical featuers to fall in [0,1]
```
   age = tf.contrib.layers.real_valued_column("age") 
```
"""

def construct_feature_columns():
  """Construct TensorFlow Feature Columns for features
  
  Returns:
    A set of feature columns
  """
  
  # Sample of creating a real-valued column.
  age = tf.contrib.layers.real_valued_column("age") 
  
  # Sample of creating a bucketized column using a real-valued column
  boundaries = get_quantile_based_boundaries(training_examples["age"], 5)
  age_buckets = tf.contrib.layers.bucketized_column(age, boundaries)
  
 
  # Sample of creating a categorical column with known values
  gender = tf.contrib.layers.sparse_column_with_keys(
    column_name="gender", keys=["Female", "Male"])
  
  education = tf.contrib.layers.sparse_column_with_hash_bucket(
      "education", hash_bucket_size=50)

  # Sample of a crossed_column which in this case combines a bucketized column
  # and a categorical column. In general, you can include any number of each.
  # So for example you could cross two categorical columns, or two bucketized
  # columns, two categorical columns and also a bucketized column,...
  gender_x_age_buckets = tf.contrib.layers.crossed_column(
      [gender, age_buckets], hash_bucket_size=1000)
  
  
  capital_gain = tf.contrib.layers.real_valued_column("capital_gain")
  
  cap_gain_boundaries = get_quantile_based_boundaries(training_examples["capital_gain"], 100)
  cap_gain_buckets = tf.contrib.layers.bucketized_column(capital_gain, cap_gain_boundaries)
  
  
  capital_loss = tf.contrib.layers.real_valued_column("capital_loss")
  
  cap_loss_boundaries = get_quantile_based_boundaries(training_examples["capital_loss"], 100)
  cap_loss_buckets = tf.contrib.layers.bucketized_column(capital_gain, cap_gain_boundaries)
  
  
  cap_gain_x_cap_loss = tf.contrib.layers.crossed_column(
      [cap_gain_buckets, cap_loss_buckets], hash_bucket_size=1000)

  # In this sample code, note that while the real-valued column age was defined
  # in order to define the bucketized column age_buckets, the real-valued
  # feature age is not being included in feature_columns.  If you would like
  # the real-valued feature age to also be used in training the model then you
  # would add that to the set of feature columns being returned.
  feature_columns=[age_buckets, gender, gender_x_age_buckets, education, cap_gain_x_cap_loss]
  
  return feature_columns

"""### Functions to help visualize our results

Since this is a classification problem, the calibration plot is not a good visualization tool. Instead we use an **ROC curve** in which the x-axis is the false positive rate and the y-axis is the true positive rate.  An ROC curve is a very good way to visualize the quality of a binary classifier and also to pick a threshold when making a binary prediction.  Recall that the line `x=y` corresponds to a random classifier.  **AUC** (the area under the ROC curve) has the nice *probabilistic interpretation that a random positive example is predicted to be more likely to be positive than a random negative example*.

Our implementation of `make_roc_curve` uses the [sklearn metrics](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics) class. There are a lot of tools already available within Python libraries so be sure and look for those.
"""

def make_roc_curve(predictions, targets):
  """ Plots an ROC curve for the provided predictions and targets.

  Args:
    predictions: the probability that the example has label 1.
    targets: a list of the target values being predicted that must be the
             same length as predictions.
  """  
  false_positive_rate, true_positive_rate, thresholds = metrics.roc_curve(
      targets, predictions)
  
  plt.ylabel("true positive rate")
  plt.xlabel("false positive rate")
  plt.plot(false_positive_rate, true_positive_rate)
  
def plot_learning_curve(training_losses, validation_losses):
  """ Plot the learning curve.
  
  Args:
    training_loses: a list of training losses to plot.
    validation_losses: a list of validation losses to plot.
  """        
  plt.ylabel('Loss')
  plt.xlabel('Training Steps')
  plt.plot(training_losses, label="training")
  plt.plot(validation_losses, label="validation")
  plt.legend(loc=1)

"""### Construct Feature Columns ###

There is a change needed in moving from a linear model to a DNN in the way the feature columns are defined.  For real-valued featuers, no changes are needed. However, in order to use categorical features in a DNN you must introduce embedding layers, which are special hidden units that learn embeddings converting the sparse categorical features into a d-dimensional embedding where similar features are nearby. In order to help get you started in training a DNN, we have provided an implementation for `construct_feature_columns`.  You are welcome to make modifications to this function.
"""

def construct_feature_columns():
  """Construct TensorFlow Feature Columns for features
  
  Returns:
    A set of feature columns.
  """ 
  age = tf.contrib.layers.real_valued_column("age") 
  education_num = tf.contrib.layers.real_valued_column("education_num") 
  capital_gain = tf.contrib.layers.real_valued_column("capital_gain") 
  capital_loss = tf.contrib.layers.real_valued_column("capital_loss")
  hours_per_week = tf.contrib.layers.real_valued_column("hours_per_week") 
  
  # Sample of creating a categorical column with known values
  gender = tf.contrib.layers.sparse_column_with_keys(
    column_name="gender", keys=["Female", "Male"])
  
  race = tf.contrib.layers.sparse_column_with_keys(
    column_name="race", keys=["White", "Asian-Pac-Islander",
                              "Amer-Indian-Eskimo", "Other", "Black"])
  
  # Sample of creating a categorical columns with a hash bucket    
  education = tf.contrib.layers.sparse_column_with_hash_bucket(
      "education", hash_bucket_size=50)
  
  marital_status = tf.contrib.layers.sparse_column_with_hash_bucket(
      "marital_status", hash_bucket_size=20)
    
  relationship = tf.contrib.layers.sparse_column_with_hash_bucket(
      "relationship", hash_bucket_size=20)
    
  occupation = tf.contrib.layers.sparse_column_with_hash_bucket(
      "occupation", hash_bucket_size=50)
  
  native_country = tf.contrib.layers.sparse_column_with_hash_bucket(
      "native_country", hash_bucket_size=50)
  
  workclass = tf.contrib.layers.sparse_column_with_hash_bucket(
      "workclass", hash_bucket_size=50)
 
  gender = tf.contrib.layers.embedding_column(gender, dimension=2)
  race = tf.contrib.layers.embedding_column(race, dimension=4)
  education = tf.contrib.layers.embedding_column(education, dimension=4)
  marital_status = tf.contrib.layers.embedding_column(
      marital_status, dimension=4)
  relationship = tf.contrib.layers.embedding_column(relationship, dimension=2)
  occupation = tf.contrib.layers.embedding_column(occupation, dimension=4)
  native_country = tf.contrib.layers.embedding_column(native_country,
                                                      dimension=4)
  workclass = tf.contrib.layers.embedding_column(workclass, dimension=4)
    
  feature_columns=[age, education_num, capital_gain, capital_loss, 
                   hours_per_week, gender, race, education, marital_status,
                   relationship, occupation, native_country, workclass]

  return feature_columns

"""## Task 1: Train a DNN Model (5 points)

Below is the code to define a DNN classifier. Observe it is very similar to `define_linear_classifier` when using [FtrlOptimizer](https://www.tensorflow.org/api_docs/python/tf/train/FtrlOptimizer) except that we replace the LinearClassifier with a [DNNClassifier](https://www.tensorflow.org/api_docs/python/tf/contrib/learn/DNNClassifier), which requires you to specify the hidden units.

Your task in this lab is to explore training a DNN.  We encourage you to vary the number of hidden layers and their sizes, the number of embedding dimensions within `construct_feature_columns`, and the L1 and L2-regularization.  For each model variation, you will need to find the best learning rate and number of steps for training the model.

Your submission for this lab should include ROC curves or some alternate method of comparing at least 3 or 4 models with a discussion of what you learned from your exploration. You should look at aspects such as the performance, the model size, and how long it took to train.  Please include at least one model with a single layer, and at least one model with 3 layers.  The sample code has 2 layers.
"""

def define_DNN_classifier(learning_rate,
                          hidden_units,
                          l1_regularization_strength=0.0,
                          l2_regularization_strength=0.0):
  """ Defines a DNN classifer.
  
  Args:
    learning_rate: A `float`, the learning rate
    hidden_units: A `list` providing the hidden unit sizes
    l1_regularization_strength: A `float`, l1 regularization strength
    l2_regularization_strength: A `float`, l2 regularization strength
    
  Returns:
    A DNN created with the given parameters
  """
  
  # Use the Follow the Regularized Leader Optimizer
  optimizer=tf.train.FtrlOptimizer(
      learning_rate=learning_rate,
      l1_regularization_strength=l1_regularization_strength,
      l2_regularization_strength=l2_regularization_strength)
  
  DNN_classifier = tf.contrib.learn.DNNClassifier(
    feature_columns=construct_feature_columns(),
    hidden_units=hidden_units,
    optimizer=optimizer, gradient_clip_norm=5.0
  )
  return DNN_classifier

"""Below is the code to train the DNN with a two layer DNN, the first layer has 10 units and the second layer has 5 units.  This assumes you have included the definition of `train_model` which will be just like in previous labs."""

LEARNING_RATE = 0.1
L1_REGULARIZATION_STRENGTH = 0
L2_REGULARIZATION_STRENGTH = 0.1
HIDDEN_UNITS = [5]
STEPS = 5000

DNN_classifier = define_DNN_classifier(
    learning_rate = LEARNING_RATE,
    hidden_units = HIDDEN_UNITS,
    l1_regularization_strength = L1_REGULARIZATION_STRENGTH,
    l2_regularization_strength = L2_REGULARIZATION_STRENGTH
)
DNN_classifier = train_model(DNN_classifier, steps=STEPS)

"""Here is a method that you can use to compute the model size, which is the number of non-zero weights in the trained model.  Remember that there are model weights within the embedding layers as well as the DNN layers.

### Calculate the model size

To calculate the model size, we simply count the number of parameters that are non-zero. We provide a helper function below to do that. The function uses intimate knowledge of the Estimators API - don't worry about understanding how it works.
"""

def model_size(estimator):
  variables = estimator.get_variable_names()
  size = 0
  for variable in variables:
    if not any(x in variable 
               for x in ['global_step',
                         'centered_bias_weight',
                         'bias_weight',
                         'Ftrl']
              ):
      size += np.count_nonzero(estimator.get_variable_value(variable))
  return size

#print "the model size is " + str(model_size(linear_classifier))

"""### Modifying the Method to Plot ROC curves

We introduce a function to create a single plot with multiple ROC curves.  We also recommend that you look at the learning curve for the training and validation loses but will leave it to you to add that function here.
"""

def plot_multiple_roc_curves(model_predictions, targets, model_names=[]):
  """ Creates a plot with a provided set of ROC curves
  Args:
    model_predictions: a list of lists, where sublist i is a list of
             predictions for model i.  For each sublist of model predictions,
             the jth element is the probability that example j is positive.
    targets: a list of the target values being predicted that must be the same
             length as each sublist in model_predictions.  Observe that the
             targets are the same for all models.
    model_names: a list the same length as model_predictions (or empty) where
             the ith element is the name to use for model i in the plot legend.
             
  """
  
  plt.ylabel("true positive rate")
  plt.xlabel("false positive rate")
  
  for i in range (0, len(model_predictions)):
      false_positive_rate, true_positive_rate, thresholds = metrics.roc_curve(
          targets, model_predictions[i])
      label = ""
      if len(model_names) > i:
        label = model_names[i]
      plt.plot(false_positive_rate, true_positive_rate, label=label)
  if len(model_names) > 0:
    plt.legend(loc=4)

validation_probs = []
model_names = []

size = model_size(DNN_classifier)
validation_probabilities = np.array(list(DNN_classifier.predict_proba(
    input_fn=eval_input_fn)))
validation_probs.append(validation_probabilities[:, 1])
model_name = ("DNN" + str(HIDDEN_UNITS) + 
             ", L1=" + str(L1_REGULARIZATION_STRENGTH) +
             ", L2=" + str(L2_REGULARIZATION_STRENGTH) + 
             ", size="+str(size))
model_names.append(model_name)

evaluation_metrics = DNN_classifier.evaluate(
 input_fn=test_input_fn, steps=1)

print "AUC on the test set: %0.2f" % evaluation_metrics['auc']
print "Accuracy on the test set: %0.2f" % evaluation_metrics['accuracy']
print "Loss on the test set: %0.2f" % evaluation_metrics['loss']

evaluation_metrics = DNN_classifier.evaluate(
 input_fn=test_input_fn, steps=1)

plot_multiple_roc_curves(validation_probs, validation_examples[LABEL], model_names)