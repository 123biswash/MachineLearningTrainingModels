# -*- coding: utf-8 -*-
"""Copy of Lab 12: Learning Embeddings.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1f59AC0Ikk5QilPl9hEJ7z0OEy64PmR7z

#### Copyright 2017 Google LLC.
"""

# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""# Lab 12: Learning Embeddings

**Learning Objectives:**
* Represent movie-review as a bag of words
* Implement a sentiment-analysis linear model
* Implement a sentiment-analysis DNN model using an embedding that projects data into two dimensions
* Visualize the embedding to see what the model has learned about the relationships between words

In this exercise, we'll explore sparse data and work with embeddings using text data from movie reviews (from the [ACL 2011 IMDB dataset](http://ai.stanford.edu/~amaas/data/sentiment/)). This data has already been processed into  [Tensor Flow Example](https://www.tensorflow.org/api_docs/python/tf/train/Example) format.

### Standard Set-up

We begin with the standard set-up.
"""

import math

from IPython import display
from matplotlib import cm
from matplotlib import gridspec
from matplotlib import pyplot as plt
import numpy as np
import pandas as pd
from mpl_toolkits.mplot3d import Axes3D
from sklearn import metrics
import tempfile
import tensorflow as tf
from tensorflow.contrib.learn.python.learn import learn_io, estimator
import urllib

# This line increases the amount of logging when there is an error.  You can
# remove it if you want less logging.
tf.logging.set_verbosity(tf.logging.ERROR)

# Set the output display to have two digits for decimal places, for display
# readability only and limit it to printing 15 rows.
pd.options.display.float_format = '{:.2f}'.format
pd.options.display.max_rows = 15

"""## Downloading Data

We use `wget` to load the data which is formatted as a [Tensor Flow Example](https://www.tensorflow.org/api_docs/python/tf/train/Example), which is a flexible format that can be used to input data for training models.
"""

!wget https://storage.googleapis.com/advanced-solutions-lab/mlcc/sparse_data_embedding/test.tfrecord -O /tmp/test.tfrecord
!wget https://storage.googleapis.com/advanced-solutions-lab/mlcc/sparse_data_embedding/train.tfrecord -O /tmp/train.tfrecord

"""## Training a Sentiment-Analysis Model

Let's train a sentiment-analysis model on this data that predicts if a review is generally *favorable* (label of 1) or *unfavorable* (label of 0).

To do so, we'll turn our string-value `terms` into sparse feature vectors by using a *vocabulary*, a list of each term we expect to see in our data. For the purposes of this exercise, we've created a small vocabulary that focuses on a limited set of terms. Most of these terms were found to be strongly indicative of *favorable* or *unfavorable*, but some were just added because they're interesting. Terms in an example that don't appear in the vocabulary are not used.

**NOTE:** *We could of course use a larger vocabulary, and there are special tools for creating these. In addition, instead of just dropping terms that are not in the vocabulary, we can introduce a small number of OOV (out-of-vocabulary) buckets to which you can hash the terms not in the vocabulary. We can also use a feature column with hashing, as in previous labs, instead of creating an explicit vocabulary. This works well in practice, but loses interpretability, which is useful for this exercise.*
"""

informative_terms = [ "bad", "great", "best", "worst", "fun", "beautiful",
                      "excellent", "poor", "boring", "awful", "terrible",
                      "definitely", "perfect", "liked", "worse", "waste",
                      "entertaining", "loved", "unfortunately", "amazing",
                      "enjoyed", "favorite", "horrible", "brilliant", "highly",
                      "simple", "annoying", "today", "hilarious", "enjoyable",
                      "dull", "fantastic", "poorly", "fails", "disappointing",
                      "disappointment", "not", "him", "her", "good", "time",
                      "sad", "exciting", "slow", "movie", "film", "action",
                      "comedy", "drama", "fabulous"]
print len(informative_terms)

"""***Defining the Input Function and Feature Columns***

One advantage of using a TensorFlow example as the input format is that you can very flexibly modify which attributes to use as the features and as the label.  The provided code parses the example into the features and label.

Another change is that in each training step, we commpute the gradient on a subset (called a *batch*) of examples which makes training faster as the size of the data set grows since it is not efficient to process all examples in computing the gradient for each gradient update. Typically the **batch size** is a hyperparameter along with the learning rate and number of steps to train. While it is not needed for this lab, you are welcome to add `batch_size` as a hyperparameter to train if you'd like. If you are interested, more information about the methods used here can be found in the TensorFlow documentation.  However, it is not necessary for you to change these methods for this lab.
"""

# First, set up a dictionary that allows us to parse out the features from the
# tf.Examples
features_to_types_dict = {
    "terms": tf.VarLenFeature(dtype=tf.string),
    "labels": tf.FixedLenFeature(shape=[1], dtype=tf.float32)}

# Create an input_fn that parses the tf.Examples from the given file pattern,
# and split them into features and targets.  We set a batch size of 250.
def _input_fn(input_file_pattern):
  features = tf.contrib.learn.io.read_batch_features(
    file_pattern=input_file_pattern,
    batch_size=250,
    features=features_to_types_dict,
    reader=tf.TFRecordReader)
  targets = features.pop("labels")
  return features, targets

# Create a feature column from "terms", using our informative terms.
terms_feature_column = tf.contrib.layers.sparse_column_with_keys(
    column_name="terms", keys=informative_terms)

"""***Optimizers in TensorFlow***

There has been significant research in the ML community about designing optimizers that will converge faster then SGD.  TensorFlow provides implementations for many of these making it easy to try them out to see which works best for a specific application. We encourage you to read the [TF Optimizer documentation](http://tflearn.org/optimizers/) to learn more.  For this lab, we have found that Adagrad, which adaptively sets the learning rate independently for each feature, gives good performance, so we're using that in the provided code. You are welcome to try other optimizers.
"""

def define_linear_classifier(learning_rate):
  """ Defines a linear classifer.
  
  Args:
    learning_rate: A `float`, the learning rate
    
  Returns:
    A linear classifier created with the given parameters
  """
  
  # Use the Adagrad Optimizer
  optimizer = tf.train.AdagradOptimizer(
      learning_rate=learning_rate)
  
  linear_classifier = tf.contrib.learn.LinearClassifier(
    feature_columns=[terms_feature_column],
    optimizer=optimizer,
    gradient_clip_norm=5.0
  )  
  return linear_classifier

"""**Train Model**

We have modified `train_model` to use the `_input_fn` method that has been provided.  We select which data set is used via a lambda function.  In addition we use the evaluation metrics provided within TF to compute the evaluation metrics used to create the learning curve. Also, just for the purpose of this lab, we use the test set as our validation set.  However, for a real application you would want to keep an independent test set.
"""

# For your convenience the method plot the learning the learning curve.
def plot_learning_curve(training_losses, validation_losses):
  """ Plot the learning curve.
  
  Args:
    training_loses: a list of training losses to plot.
    validation_losses: a list of validation losses to plot.
  """        
  plt.ylabel('Loss')
  plt.xlabel('Training Steps')
  plt.plot(training_losses, label="training")
  plt.plot(validation_losses, label="validation")
  plt.legend(loc=1)
  
def train_model(model, steps):
  """Trains a linear classifier.
  
  Args:
    model: The model to train.
    steps: A non-zero `int`, the total number of training steps.
    
  Returns:
    The trained model.
  """
  # In order to see how the model evolves as we train it, we divide the
  # steps into periods and show the model after each period.
  periods = 10
  steps_per_period = steps / periods
  
  # Train the model, but do so inside a loop so that we can periodically assess
  # loss metrics.  We store the training and validation losses so we can
  # generate a learning curve.
  print "Training model..."
  training_losses = []
  validation_losses = []

  for period in range (0, periods):
    # Call fit to train the model for steps_per_period steps.
    model.fit(input_fn=lambda: _input_fn("/tmp/train.tfrecord"),
              steps=steps_per_period)
    
    # Compute the loss between the predictions and the correct labels, append
    # the training and validation loss to the list of losses used to generate
    # the learning curve after training is complete and print the current
    # training loss.
    training_evaluation_metrics = model.evaluate(
        input_fn=lambda: _input_fn("/tmp/train.tfrecord"),
        steps=1)
    training_loss = training_evaluation_metrics['loss']
    
    validation_evaluation_metrics = model.evaluate(
        input_fn=lambda: _input_fn("/tmp/test.tfrecord"), steps=1)
    validation_loss = validation_evaluation_metrics['loss']
    training_losses.append(training_loss) 
    validation_losses.append(validation_loss) 
    print "  Training loss after period %02d : %0.3f" % (period, training_loss)
      
  # Now that training is done print the final training and validation losses.  
  print "Final Training Loss: %0.3f" % training_loss
  print "Final Validation Loss: %0.3f" % validation_loss 
  
  # Generate a figure with the learning curve.
  plt.figure(figsize=(10, 5))
  plt.title("Learning Curve (Loss vs time)")
  plot_learning_curve(training_losses, validation_losses)
  return model

"""## Task 1: Train a Linear Model (1 point)

First, you will train a linear model on the 50 word vocabulary to predict if a review is positive or negative. The provided hyperparameters for this lab yield reasonable models, so you shouldn't need to spend too long adjusting them. With the larger data set and use of the batch size in Adaboost you will find the learning curves are not as smooth as you've seen in earlier labs.
"""

LEARNING_RATE = 0.025
STEPS = 100

linear_classifier = define_linear_classifier(
    learning_rate = LEARNING_RATE)
linear_classifier = train_model(linear_classifier, steps=STEPS)

evaluation_metrics = linear_classifier.evaluate(
 input_fn=lambda: _input_fn("/tmp/test.tfrecord"), steps=1)

print "AUC on the test set: %0.2f" % evaluation_metrics['auc']
print "Accuracy on the test set: %0.2f" % evaluation_metrics['accuracy']
print "Loss on the test set: %0.2f" % evaluation_metrics['loss']

"""## Task 2: Training Word Embeddings using a DNN model (1 point)

Next you will train a DNNClassifier over the 50 word vocabulary using a 2-dimensional embedding column.  Then in the next task we will plot the embeddings as a way to visualize them.

**NOTE:** *In practice, we might project to dimensions higher than 2, like 50 or 100.  But for now, 2 dimensions is easy to visualize.*
"""

def define_DNN_classifier(learning_rate, hidden_units):
  """ Defines a DNN classifer.
  
  Args:
    learning_rate: A `float`, the learning rate
    hidden_units: A `list` providing the hidden unit sizes
    
  Returns:
    A DNN crated with the given parameters
  """
  
  # Use the Adagrad Optimizer
  optimizer = tf.train.AdagradOptimizer(
      learning_rate=learning_rate)
  
  DNN_classifier = tf.contrib.learn.DNNClassifier(
    feature_columns=[tf.feature_column.embedding_column(
        terms_feature_column, dimension=2)],
    hidden_units=hidden_units,
    optimizer=optimizer, gradient_clip_norm=5.0
  )
  return DNN_classifier

LEARNING_RATE = 0.1
HIDDEN_UNITS = [20,20]
STEPS = 2000

DNN_classifier = define_DNN_classifier(
    learning_rate = LEARNING_RATE,
    hidden_units=HIDDEN_UNITS)

DNN_classifier = train_model(DNN_classifier, steps=STEPS)

evaluation_metrics = DNN_classifier.evaluate(
 input_fn=lambda: _input_fn("/tmp/test.tfrecord"), steps=1)

print "AUC on the test set: %0.2f" % evaluation_metrics['auc']
print "Accuracy on the test set: %0.2f" % evaluation_metrics['accuracy']
print "Loss on the test set: %0.2f" % evaluation_metrics['loss']

"""## Task 3: Examine the embedding (3 points)

Let's now take a look at the actual embedding space, and see where the terms end up in it.

First, let's see where we can get the embedding weights from the model.  You might find it informative to manually check the various layers and shapes to make sure everything is connected the way you would expect it would be.  You can use `get_variable_names()` to see the variable names for the model weights.
"""

DNN_classifier.get_variable_value('dnn/input_from_feature_columns/input_layer/terms_embedding/embedding_weights').shape

"""***Getting and Visualizing the Embeddings***

We now provide a method that will get the embedding weights from the model and create a 2d visualization of the word embeddings learned when training the sentiment-analysis model.  If you are familar with doing 3d plots in Python you could do a similar thing for visualizing a 3d embedding (given that you trained a model with a 3-dimensional embedding layer).
"""

embedding_matrix = DNN_classifier.get_variable_value(
    'dnn/input_from_feature_columns/input_layer/terms_embedding/embedding_weights')

for term_index in range(len(informative_terms)):
  # Create a one-hot encoding for our term.  It has 0's everywhere, except for
  # a single 1 in the coordinate that corresponds to that term.
  term_vector = np.zeros(len(informative_terms))
  term_vector[term_index] = 1
  # We'll now project that one-hot vector into the embedding space.
  embedding_xy = np.matmul(term_vector, embedding_matrix)
  plt.text(embedding_xy[0],
           embedding_xy[1],
           informative_terms[term_index])

# Do a little set-up to make sure the plot displays nicely.
plt.rcParams["figure.figsize"] = (25, 25)
plt.xlim(1.2 * embedding_matrix.min(), 1.2 * embedding_matrix.max())
plt.ylim(1.2 * embedding_matrix.min(), 1.2 * embedding_matrix.max())
plt.show()

'''
Answer the following questions here:

1. Run the following code to see the embedding we trained in **Task 3**. Do
words end up where you'd expect?

2. Re-train the model by rerunning the code in **Task 3**, and then run the
embedding visualization below again. What stays the same? What changes?

3. Finally, re-train the model again using only 10 steps (which will yield
a terrible model). Run the embedding visualization below again.
What do you see now, and why are the embeddings like that?  What do the
embeddings look like if you train it 100 steps?
'''

"""## A final word

We may have gotten a DNN solution with an embedding that was better than our original linear model, but the linear model was also pretty good and was quite a bit faster to train. Linear models train more quickly because they do not have nearly as many parameters to update or layers to backprop through.

In some applications, the speed of linear models may be a game changer, or linear models may be perfectly sufficient from a quality standpoint. In other areas, the additional model complexity and capacity provided by DNNs might be more important. When defining your model architecture, remember to explore your problem sufficiently so that you know which space you're in.

## Optional Extra Credit Task (1 point):

There's a full vocabulary file with all 30716 terms for this data set that you can use at: https://storage.googleapis.com/advanced-solutions-lab/mlcc/sparse_data_embedding/terms.txt. You can use all of these terms using the `sparse_column_with_vocabulary_file` feature column.
"""

!wget https://storage.googleapis.com/advanced-solutions-lab/mlcc/sparse_data_embedding/terms.txt -O /tmp/terms.txt

# Create a feature column from "terms", using a full vocabulary file.
informative_terms = None
with open("/tmp/terms.txt", 'r') as f:
  # Convert it to set first to remove duplicates.
  informative_terms = list(set(f.read().split()))
print len(informative_terms)